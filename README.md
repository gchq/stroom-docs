![Stroom](resources/logo.png)

If you'd like to jump straight in then see the [Quick Start Guide](quick-start-guide/quick-start.md), alternatively you can find the full documentation [here](SUMMARY.md).

# Stroom

Stroom is a data processing, storage and analysis platform. It is scalable - just add more CPUs / servers for greater throughput. It is suitable for processing high volume data such as system logs, to provide valuable insights into IT performance and usage.

Stroom provides a number of powerful capabilities:

* **Data ingest.** Receive and store large volumes of data such as native format logs. Ingested data is always available in its raw form.
* **Data transformation pipelines.** Create sequences of XSL and text operations, in order to normalise or export data in any format. It is possible to enrich data using lookups and reference data.
* **Integrated transformation development.** Easily add new data formats and debug the transformations if they don't work as expected.
* **Scalable Search.** Create multiple indexes with different retention periods. These can be sharded across your cluster.
* **Statistics.** Record counts or values of items over time, providing answers to questions such as "how many times has a specific machine provided data in the last hour/day/month?"
* **Dashboards.** Run queries against your indexes or statistics and view the results within custom visualisations.

# Benefits

System event data can come from many kinds of technology, this makes it highly heterogeneous with many different formats in use. As technologies are invented, new event types and log formats must be understood and processed correctly. Technology changes so rapidly that the auditing team risks being left behind.

Stroom is designed to offer a way to mitigate this risk, and has matured into an application that scales well to billions of events a day - sufficient to ingest and process the system events generated by the IT of a large organisation.

The person who introduces a new log format is probably best placed to describe it. Stroom provides these experts with tools that make it easy to normalise data, essentially crowdsourcing the problem. An organisation can ask their employees to configure Stroom whenever they introduce a new technology, and have confidence that it will be able to be properly audited.

# Architecture

Stroom is a Java web application that runs on _Apache Tomcat_, with _Apache Lucene_ indexes over a compressed data store. It uses a _MySQL_ RDBMS to persist application configuration and metadata. 

Currently Stroom has only been tested with _Google Chrome_. For this reason some functionality may not work correctly in other browsers. Now that Stroom is an open source project, support for other browsers will be improved.

There are several optional components for different use cases:

* **Stroom Proxy** - An application that receives and forwards data to Stroom.
* **Stroom Agent** - An application that extracts data from sources. 
* **Logging Events XML Schema** - A common language for describing audit events.
* **Content Packs** - Transformation packages for standard log formats (e.g. Windows, Linux) into Logging Events XML.

# Screenshots

Some screenshots of the application can be seen [here](screenshots.md).

# State of the Project

Stroom has recently undergone a significant code refactor and change to its security model. As a result v5.0.0, the forthcoming version, is currently in beta and is still being tested. We would recommend waiting for a stable release before deploying into a production environment.

# Future

Although Stroom is a mature product it is receiving more active development effort than ever. Work is underway to evolve the existing architecture and add new features:

* A rule engine for notifying analysts about particular event scenarios
* Scalable temporal state storage that could be used by rules or dashboards
* New visualisations to improve analysis
* A modularised, micro-service-based architecture
* Further integration with the Hadoop ecosystem
