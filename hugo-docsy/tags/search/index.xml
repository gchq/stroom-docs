<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stroom â€“ search</title>
    <link>/stroom-docs/hugo-docsy/tags/search/</link>
    <description>Recent content in search on Stroom</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 12 Jul 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/stroom-docs/hugo-docsy/tags/search/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Elasticsearch integration</title>
      <link>/stroom-docs/hugo-docsy/docs/howtos/search/elasticsearch/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/stroom-docs/hugo-docsy/docs/howtos/search/elasticsearch/</guid>
      <description>
        
        
        &lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Stroom v6.1 can pass data to Elasticsearch for indexing.
Indices created using this process (i.e. those containing a &lt;code&gt;StreamId&lt;/code&gt; and &lt;code&gt;EventId&lt;/code&gt; corresponding to a particular Stroom instance)
are searchable via a Stroom &lt;em&gt;dashboard&lt;/em&gt;, much like a Stroom Lucene index.&lt;/p&gt;
&lt;p&gt;This integration provides operators with the flexibility to utilise the additional capabilities of Elasticsearch,
(like clustering and replication) and expose indexed data for consumption by external analytic or processing tools.&lt;/p&gt;
&lt;p&gt;This guide will take you through creating an Elasticsearch index, setting up an indexing pipeline, activating a stream processor and searching the indexed data in both Stroom and Elasticsearch.&lt;/p&gt;
&lt;h3 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;You have created an Elasticsearch cluster.
For test purposes, you can quickly create a single-node cluster using Docker by following the steps in the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-dev-mode&#34;&gt;Elasticsearch Docs (external link)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The Elasticsearch cluster is reachable via HTTP/S from all Stroom nodes participating in &lt;a href=&#34;../../stroom-docs/hugo-docsy/docs/quick-start-guide/running/&#34;&gt;stream processing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Elasticsearch security is disabled.&lt;/li&gt;
&lt;li&gt;You have a feed containing &lt;code&gt;Event&lt;/code&gt; data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;key-differences&#34;&gt;Key differences&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Unlike with &lt;a href=&#34;../../stroom-docs/hugo-docsy/docs/howtos/search/solr/&#34;&gt;Solr indexing&lt;/a&gt;, Elasticsearch field mappings are managed outside of Stroom, usually via the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html#mappings&#34;&gt;REST API (external link)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Aside from creating the mandatory &lt;code&gt;StreamId&lt;/code&gt; and &lt;code&gt;EventId&lt;/code&gt; field mappings, explicitly defining mappings for other fields is optional.
It is however, considered good practice to define these mappings, to ensure each field&amp;rsquo;s data type is correctly parsed and represented.
For text fields, it also pays to ensure that the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html&#34;&gt;appropriate mapping parameters are used (external link)&lt;/a&gt;,
in order to satisfy your search and analysis requirements - and meet system resource constraints.&lt;/li&gt;
&lt;li&gt;Unlike both Solr and Lucene indexing, it is not necessary to mark a field as &lt;code&gt;stored&lt;/code&gt; (i.e. storing its raw value in the inverted index).
This is because Elasticsearch stores the content of the original document in the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html&#34;&gt;&lt;code&gt;_source&lt;/code&gt; field (external link)&lt;/a&gt;,
which is retrieved when populating search results.
Provided the &lt;code&gt;_source&lt;/code&gt; field is enabled (as it is by default), a field is treated as &lt;code&gt;stored&lt;/code&gt; in Stroom and its value doesn&amp;rsquo;t need to be retrieved via an &lt;em&gt;extraction pipeline&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;indexing-data&#34;&gt;Indexing data&lt;/h2&gt;
&lt;h3 id=&#34;creating-an-index-in-elasticsearch&#34;&gt;Creating an index in Elasticsearch&lt;/h3&gt;
&lt;p&gt;The following cURL command creates an index named &lt;code&gt;stroom_test&lt;/code&gt; in Elasticsearch cluster &lt;code&gt;http://localhost:9200&lt;/code&gt; consisting of the following fields:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;StreamId&lt;/code&gt; (mandatory, must be of data type &lt;code&gt;long&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EventId&lt;/code&gt; (mandatory, must also be &lt;code&gt;long&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Name&lt;/code&gt; (text). Uses the default analyzer, which tokenizes the text for matching on terms.
&lt;code&gt;fielddata&lt;/code&gt; is enabled, which allows for &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/text.html#fielddata-mapping-param&#34;&gt;aggregating on these terms (external link)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;State&lt;/code&gt; (keyword). Supports exact matching.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The created index consists of &lt;code&gt;5&lt;/code&gt; shards.
Note that the shard count cannot be changed after index creation, without a reindex.
See &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/size-your-shards.html&#34;&gt;this guide (external link)&lt;/a&gt; on shard sizing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X PUT &amp;quot;http://localhost:9200/stroom_test?pretty&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39;
   {
      &amp;quot;settings&amp;quot;: {
        &amp;quot;number_of_shards&amp;quot;: 5
      },
      &amp;quot;mappings&amp;quot;: {
        &amp;quot;properties&amp;quot;: {
          &amp;quot;StreamId&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;
          },
          &amp;quot;EventId&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;long&amp;quot;
          },
          &amp;quot;Name&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
            &amp;quot;fielddata&amp;quot;: true
          },
          &amp;quot;State&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;,
            &amp;quot;fielddata&amp;quot;: true
          }
        }
      }
    }
&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After creating the index, you can add additional field mappings.
Note the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-put-mapping.html#updating-field-mappings&#34;&gt;limitations (external link)&lt;/a&gt; in doing so, particularly the fact that it will not cause existing documents to be re-indexed.
It is worthwhile to test index mappings on a subset of data before committing to indexing a large event feed, to ensure the resulting search experience meets your requirements.&lt;/p&gt;
&lt;h3 id=&#34;registering-the-index-in-stroom&#34;&gt;Registering the index in Stroom&lt;/h3&gt;
&lt;p&gt;This step creates an &lt;em&gt;Elasticsearch Index&lt;/em&gt; in the &lt;em&gt;Stroom Tree&lt;/em&gt; and tells Stroom how to connect to your Elasticsearch cluster
and index. Note that this process needs to be repeated for each index you create.&lt;/p&gt;
&lt;h4 id=&#34;steps&#34;&gt;Steps&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Right-click on the folder in the &lt;em&gt;Explorer Tree&lt;/em&gt; where you wish to create the index&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;New&lt;/code&gt; / &lt;code&gt;Elasticsearch Index&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enter a valid name for the index. It is a good idea to choose one that reflects either the feed name being indexed, or if
indexing multiple feeds, the nature of data they represent.&lt;/li&gt;
&lt;li&gt;In the index tab that just opened:
&lt;ol&gt;
&lt;li&gt;Select the &lt;code&gt;Settings&lt;/code&gt; tab&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;Index&lt;/code&gt; to the name of the index in Elasticsearch (e.g. &lt;code&gt;stroom_test&lt;/code&gt; from the previous example)&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;Connection URLs&lt;/code&gt; to one or more Elasticsearch node URLs. If multiple, separate each URL with &lt;code&gt;,&lt;/code&gt;.
For example, a URL like &lt;code&gt;http://data-0.elastic:9200,http://data-1.elastic:9200&lt;/code&gt; will balance requests to two data nodes
within an Elasticsearch cluster. See &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html&#34;&gt;this document&lt;/a&gt; for guidance on node roles.&lt;/li&gt;
&lt;li&gt;Click &lt;code&gt;Test Connection&lt;/code&gt;. If the connection succeeds, and the index is found, a dialog is shown indicating
the test was successful. Otherwise, an error message is displayed.&lt;/li&gt;
&lt;li&gt;If the test succeeded, click the &lt;em&gt;save&lt;/em&gt; button in the top-left. The &lt;code&gt;Fields&lt;/code&gt; tab will now be populated with fields from
the Elasticsearch index.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;alert alert-primary&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note&lt;/h4&gt;

    The field mappings list is only updated when index settings are changed, or a Stroom indexing or search task begins.
The refresh button in the &lt;code&gt;Fields&lt;/code&gt; tab does not have any effect.

&lt;/div&gt;


&lt;h3 id=&#34;setting-index-retention&#34;&gt;Setting index retention&lt;/h3&gt;
&lt;p&gt;As with Solr indexing, index document retention is determined by defining a Stroom query.&lt;/p&gt;
&lt;p&gt;Setting a retention query is optional and by default, documents will be retained in an index indefinitely.&lt;/p&gt;
&lt;p&gt;It is recommended for indices containing events spanning long periods of time, that &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html&#34;&gt;Elasticsearch Index Lifecycle Management (external link)&lt;/a&gt;
be used instead. The capabilities provided, such as automatic rollover to warm or cold storage tiers, are well worth considering, especially in high-volume production clusters.&lt;/p&gt;
&lt;h4 id=&#34;considerations-when-implementing-ilm&#34;&gt;Considerations when implementing ILM&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;It is recommended that &lt;em&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/data-streams.html&#34;&gt;data streams&lt;/a&gt;&lt;/em&gt; are used when
indexing data. These allow easier rollover and work well with ILM policies. A &lt;em&gt;data stream&lt;/em&gt; is essentially a container for multiple date-based indices
and to a search client such as Stroom, appears and is searchable like a normal Elasticsearch index.&lt;/li&gt;
&lt;li&gt;Use of &lt;em&gt;data streams&lt;/em&gt; requires that a &lt;code&gt;@timestamp&lt;/code&gt; field of type &lt;code&gt;date&lt;/code&gt; be defined for each document (instead of say, &lt;code&gt;EventTime&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Implementing ILM policies requires careful capacity planning, including anticipating search and retention requirements.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;creating-an-indexing-pipeline&#34;&gt;Creating an indexing pipeline&lt;/h3&gt;
&lt;p&gt;As with Lucene and Solr indexing pipelines, indexing data using Elasticsearch uses a pipeline filter.
This filter accepts &lt;code&gt;&amp;lt;record&amp;gt;&lt;/code&gt; elements and for each, sends a document to Elasticsearch for indexing.&lt;/p&gt;
&lt;p&gt;Each &lt;code&gt;&amp;lt;data&amp;gt;&lt;/code&gt; element contained within a &lt;code&gt;&amp;lt;record&amp;gt;&lt;/code&gt; sets the document field name and value. You should ensure the &lt;code&gt;name&lt;/code&gt; attribute
of each &lt;code&gt;&amp;lt;data&amp;gt;&lt;/code&gt; element exactly matches the mapping property of the Elasticsearch index you created.&lt;/p&gt;
&lt;h4 id=&#34;steps-1&#34;&gt;Steps&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Create a pipeline inheriting from the built-in &lt;code&gt;Indexing&lt;/code&gt; template.&lt;/li&gt;
&lt;li&gt;Modify the &lt;code&gt;xsltFilter&lt;/code&gt; pipeline stage to output the correct &lt;code&gt;&amp;lt;records&amp;gt;&lt;/code&gt; XML (see the &lt;a href=&#34;../../stroom-docs/hugo-docsy/docs/quick-start-guide/indexing/&#34;&gt;Quick-Start Guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Delete the default &lt;code&gt;indexingFilter&lt;/code&gt; and in its place, create an &lt;code&gt;ElasticIndexingFilter&lt;/code&gt; (see screenshot below).&lt;/li&gt;
&lt;li&gt;Review and set the following properties:
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;batchSize&lt;/code&gt; (default: &lt;code&gt;10,000&lt;/code&gt;). Number of documents to send in a single request to the Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html&#34;&gt;Bulk API (external link)&lt;/a&gt;.
Should usually be set to &lt;code&gt;1,000&lt;/code&gt; or more.
The higher the number, the more memory is required by both Stroom and Elasticsearch when sending or receiving the request.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;index&lt;/code&gt; (required). Set this to the target Elasticsearch index in the Stroom &lt;em&gt;Explorer Tree&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;refreshAfterEachBatch&lt;/code&gt; (default: &lt;code&gt;false&lt;/code&gt;). Refreshes the Elasticsearch index after each batch has finished processing.
This makes any documents ingested in the batch available for searching.
Unless search results are needed in near-real-time, it is recommended this be set to &lt;code&gt;false&lt;/code&gt; and the index refresh interval be set to an appropriate value.
See &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html#_unset_or_increase_the_refresh_interval&#34;&gt;this document (external link)&lt;/a&gt; for guidance on optimising indexing performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;







  
  
  
  
  







  



&lt;div class=&#34;card rounded shadow-stroom p-2 td-post-card mb-4 mt-4&#34; style=&#34;width: fit-content;&#34;&gt;

  &lt;a title=&#34;images/HOWTOs/Elastic-Add-Pipeline-Filter.png&#34; href=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/Elastic-Add-Pipeline-Filter.png&#34;&gt;
    &lt;figure style=&#34;margin-block-end: 0px&#34; &gt;
      
      &lt;img class=&#34;card-img-top&#34; src=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/Elastic-Add-Pipeline-Filter.png&#34; alt=&#34;images/HOWTOs/Elastic-Add-Pipeline-Filter.png&#34;&gt;
      

      
      &lt;div class=&#34;card-body px-0 pt-2 pb-0&#34;&gt;
        &lt;hr style=&#34;border-top: 1px solid #ddd; margin-top: 0px; margin-bottom:4px;&#34;&gt;
        &lt;figcaption class=&#34;card-text&#34; style=&#34;font-size: smaller; text-align: center;&#34;&gt;Elasticsearch indexing filter&lt;/figcaption&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;h3 id=&#34;creating-and-activating-a-stream-processor&#34;&gt;Creating and activating a stream processor&lt;/h3&gt;
&lt;p&gt;Follow the steps as in &lt;a href=&#34;../../stroom-docs/hugo-docsy/docs/quick-start-guide/indexing/&#34;&gt;this guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;checking-data-has-been-indexed&#34;&gt;Checking data has been indexed&lt;/h3&gt;
&lt;p&gt;Query Elasticsearch, checking the fields you expect are there, and of the correct data type:&lt;/p&gt;
&lt;p&gt;The following query displays five results:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X GET &amp;quot;http://localhost:9200/stroom_test/_search?size=5&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also get an exact document count, to ensure this matches the number of events you are expecting:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X GET &amp;quot;http://localhost:9200/stroom_test/_count&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information, see the Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html&#34;&gt;Search API documentation (external link)&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;reindexing-data&#34;&gt;Reindexing data&lt;/h3&gt;
&lt;p&gt;By default, the original document values are stored in an Elasticsearch index and may be used later on to re-index data (such as when a change is made to field mappings).
This is done via the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html&#34;&gt;Reindex API (external link)&lt;/a&gt;.
Provided these values have not changed, it would likely be more efficient to use this API to perform a re-index,
instead of processing data from scratch using a Stroom stream processor.&lt;/p&gt;
&lt;p&gt;On the other hand, if the content of documents being output to Elasticsearch has changed, the Elasticsearch index will need to be re-created
and the stream re-processed. Examples of where this would be required include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A new field is added to the indexing filter, which previously didn&amp;rsquo;t exist. That field needs to be searchable for all historical
events.&lt;/li&gt;
&lt;li&gt;A field is renamed&lt;/li&gt;
&lt;li&gt;A field data type is changed&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If a field is omitted from the indexing translation, there is no need for a re-index, unless you wish to reclaim the space
occupied by that field.&lt;/p&gt;
&lt;h4 id=&#34;reindexing-using-a-pipeline-processor&#34;&gt;Reindexing using a pipeline processor&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Delete the index. While it is possible to &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html&#34;&gt;delete by query (external link)&lt;/a&gt;, it is more efficient to drop the index.
Additionally, deleting by query doesn&amp;rsquo;t actually remove data from disk, until segments are merged.
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -X DELETE &amp;quot;http://localhost:9200/stroom_test&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Re-create the index (as shown earlier)&lt;/li&gt;
&lt;li&gt;Create a new pipeline processor to index the documents&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;searching&#34;&gt;Searching&lt;/h2&gt;
&lt;p&gt;Once indexed in Elasticsearch, you can search either using the &lt;em&gt;Stroom Dashboard&lt;/em&gt; user interface, or directly against
the Elasticsearch cluster.&lt;/p&gt;
&lt;p&gt;The advantage of using Stroom to search is that it allows access to the raw source data (i.e. it is not limited to what&amp;rsquo;s stored in the index).
It can also use &lt;em&gt;extraction pipelines&lt;/em&gt; to enrich search results for export in a table.&lt;/p&gt;
&lt;p&gt;Elasticsearch on the other hand, provides a rich &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html&#34;&gt;Search REST API (external link)&lt;/a&gt;
with powerful &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html&#34;&gt;aggregations&lt;/a&gt; that can be
used to generate reports and discover patterns and anomalies. It can also be readily queried using third-party tools.&lt;/p&gt;
&lt;h3 id=&#34;stroom&#34;&gt;Stroom&lt;/h3&gt;
&lt;p&gt;See the &lt;a href=&#34;../../stroom-docs/hugo-docsy/docs/quick-start-guide/dashboard/&#34;&gt;Dashboard&lt;/a&gt; page in the Quick-Start Guide.&lt;/p&gt;
&lt;p&gt;Instead of selecting a Lucene index, set the target &lt;em&gt;data source&lt;/em&gt; to the desired Elasticsearch index in the Stroom &lt;em&gt;Explorer Tree&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Once the target &lt;em&gt;data source&lt;/em&gt; has been set, the Dashboard can be used as with a Lucene or Solr index &lt;em&gt;data source&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;elasticsearch&#34;&gt;Elasticsearch&lt;/h3&gt;
&lt;p&gt;Elasticsearch queries can be performed directly against the cluster using the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html&#34;&gt;Search API (external link)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Alternatively, there are tools that make search and discovery easier and more intuitive, like &lt;a href=&#34;https://www.elastic.co/kibana&#34;&gt;Kibana (external link)&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;security&#34;&gt;Security&lt;/h2&gt;
&lt;p&gt;It is important to note that Elasticsearch data is not encrypted at rest, unless this feature is enabled and the relevant &lt;a href=&#34;https://www.elastic.co/subscriptions&#34;&gt;licensing tier (external link)&lt;/a&gt; is purchased.
Therefore, appropriate measures should be taken to control access to Elasticsearch user data at the file level.&lt;/p&gt;
&lt;p&gt;For production clusters, the Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-security.html&#34;&gt;security guidelines (external link)&lt;/a&gt; should be followed, in order to control access and ensure requests are audited.&lt;/p&gt;
&lt;p&gt;You might want to consider implementing &lt;a href=&#34;https://www.elastic.co/guide/en/kibana/current/development-security.html&#34;&gt;role-based access control (external link)&lt;/a&gt;
to prevent unauthorised users of the native Elasticsearch API or tools like Kibana, from creating, modifying or deleting data within sensitive indices.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Search</title>
      <link>/stroom-docs/hugo-docsy/docs/howtos/search/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/stroom-docs/hugo-docsy/docs/howtos/search/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: Solr integration</title>
      <link>/stroom-docs/hugo-docsy/docs/howtos/search/solr/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>/stroom-docs/hugo-docsy/docs/howtos/search/solr/</guid>
      <description>
        
        
        &lt;h2 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;You are familiar with Lucene indexing within Stroom&lt;/li&gt;
&lt;li&gt;You have some data to index&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;points-to-note&#34;&gt;Points to note&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;A Solr core is the home for exactly one Stroom index.&lt;/li&gt;
&lt;li&gt;Cores must initially be created in Solr.&lt;/li&gt;
&lt;li&gt;It is good practice to name your Solr core the same as your Stroom Index.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Start a docker container for a single solr node.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 8983:8983 --name my_solr solr
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check your Solr node. Point your browser at http://yourSolrHost:8983&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a core in Solr using the CLI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it my_solr solr create_core -c test_index
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a SolrIndex in Stroom







  
  
  
  
  







  



&lt;div class=&#34;card rounded shadow-stroom p-2 td-post-card mb-4 mt-4&#34; style=&#34;width: fit-content;&#34;&gt;

  &lt;a title=&#34;images/HOWTOs/v7/HT_SimpleSolr_NewSolrIndex.png&#34; href=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_NewSolrIndex.png&#34;&gt;
    &lt;figure style=&#34;margin-block-end: 0px&#34; &gt;
      
      &lt;img class=&#34;card-img-top&#34; src=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_NewSolrIndex.png&#34; alt=&#34;images/HOWTOs/v7/HT_SimpleSolr_NewSolrIndex.png&#34;&gt;
      

      
      &lt;div class=&#34;card-body px-0 pt-2 pb-0&#34;&gt;
        &lt;hr style=&#34;border-top: 1px solid #ddd; margin-top: 0px; margin-bottom:4px;&#34;&gt;
        &lt;figcaption class=&#34;card-text&#34; style=&#34;font-size: smaller; text-align: center;&#34;&gt;New Solr Index&lt;/figcaption&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update settings for your new Solr Index in Stroom then press &amp;ldquo;Test Connection&amp;rdquo;.
If successful then press Save.
Note the &amp;ldquo;Solr URL&amp;rdquo; field is a reference to the newly created Solr core.







  
  
  
  
  







  



&lt;div class=&#34;card rounded shadow-stroom p-2 td-post-card mb-4 mt-4&#34; style=&#34;width: fit-content;&#34;&gt;

  &lt;a title=&#34;images/HOWTOs/v7/HT_SimpleSolr_Settings.png&#34; href=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_Settings.png&#34;&gt;
    &lt;figure style=&#34;margin-block-end: 0px&#34; &gt;
      
      &lt;img class=&#34;card-img-top&#34; src=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_Settings.png&#34; alt=&#34;images/HOWTOs/v7/HT_SimpleSolr_Settings.png&#34;&gt;
      

      
      &lt;div class=&#34;card-body px-0 pt-2 pb-0&#34;&gt;
        &lt;hr style=&#34;border-top: 1px solid #ddd; margin-top: 0px; margin-bottom:4px;&#34;&gt;
        &lt;figcaption class=&#34;card-text&#34; style=&#34;font-size: smaller; text-align: center;&#34;&gt;Solr Index Settings&lt;/figcaption&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add some Index fields.
e.g.EventTime, UserId&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Retention is different in Solr, you must specify an expression that matches data that can be deleted.







  
  
  
  
  







  



&lt;div class=&#34;card rounded shadow-stroom p-2 td-post-card mb-4 mt-4&#34; style=&#34;width: fit-content;&#34;&gt;

  &lt;a title=&#34;images/HOWTOs/v7/HT_SimpleSolr_Retention.png&#34; href=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_Retention.png&#34;&gt;
    &lt;figure style=&#34;margin-block-end: 0px&#34; &gt;
      
      &lt;img class=&#34;card-img-top&#34; src=&#34;../../stroom-docs/hugo-docsy/images/HOWTOs/v7/HT_SimpleSolr_Retention.png&#34; alt=&#34;images/HOWTOs/v7/HT_SimpleSolr_Retention.png&#34;&gt;
      

      
      &lt;div class=&#34;card-body px-0 pt-2 pb-0&#34;&gt;
        &lt;hr style=&#34;border-top: 1px solid #ddd; margin-top: 0px; margin-bottom:4px;&#34;&gt;
        &lt;figcaption class=&#34;card-text&#34; style=&#34;font-size: smaller; text-align: center;&#34;&gt;Solr Retention&lt;/figcaption&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your Solr Index can now be used as per a Stroom Lucene Index.
However, your Indexing pipeline must use a SolrIndexingFilter instead of an IndexingFilter.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
  </channel>
</rss>
