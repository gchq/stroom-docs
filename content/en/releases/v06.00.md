
---
weight: 60
title: "Version 6.0"
linkTitle: "6.0"
date: 2019-08-02
description: >
  Key new features and changes present in v6.0 of Stroom and Stroom-Proxy.
---

{{% pageinfo %}}
For a detailed list of the changes in v6.0 see the {{< external-link "changelog" "https://github.com/gchq/stroom/blob/6.0/CHANGELOG.md" >}} 
{{% /pageinfo %}}

## OAuth 2.0/OpenID Connect authentication

Authentication for Stroom provided by an external service rather than a service internal to Stroom.
This change allows support for broader corporate authentication schemes and is a key requirement for enabling the future microservice architecture for Stroom.

## API keys for third party clients

Anyone wishing to make use of the data exposed by Stroom's services can request an API key.
This key acts as a password for their own applications.
It allows administrators to secure and manage access to Stroom's data.

## HBase backed statistics store

This new implementation of statistics (Stroom-Stats) provides a vastly more scalable time series DB for large scale collection of Stroom's data aggregated to various time buckets.
Stroom-Stats uses Kafka for ingesting the source data.

## Data receipt filtering

Data arriving in Stroom has meta data that can be matched against a policy so that certain actions can be taken.
This could be to receive, drop or reject the data.

Filtering of data also applies to Stroom proxy where each proxy can get a filtering policy from an upstream proxy or a Stroom instance.

## Data retention policies

The length of time that data will be retained in Strooms stream store can be defined by creating data retention rules.
These rules match streams based on their meta data and will automatically delete data once the retention period associated with the rule is exceeded.

## Dashboard linking

Links can be created in dashboards to jump to other dashboards or other external sites that provide additional contextual information.

## Search API

The search system used by Dashboards can be used via a restful API.
This provides access to data stored in search indices (including the ability to extract data) and statistics stores.
The data fetched via the search API can be received and processed via an external system.

## Kafka appender and filter

New pipeline elements for writing XML or text data to a Kafka topic.
This provides more options for using Stroom's data in other systems.
